# BERT-text_summarization

Говоря заранее, у меня не получилось до конца доделать задачу с суммаризацией. Я пробовал много моделей, какой то из них не подходил для нашего датасэта, из за того что он был на русском языке. А некоторые модели поддерживали русский язык, но не было логики генерации или суммаризации текста. Самая большая проблема в этой исследовательской работе было подобрать нужную модель, коих очень мало. Но тем не менее, был отличный опыт для меня и задача была по настоящему интересной.

Трансформер BERT - не для задачи суммаризации. Но если же вам интересно как она работает для нашей задачи, то вполне можете посмотреть мой джупитер ноутбук.

Советую использовать ту же Llama с Unsloth!
